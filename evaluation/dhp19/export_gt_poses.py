import argparse
import numpy as np
import os

from utils import mat_files
import evaluation.dhp19.utils as dhp19_utils


def extract_2d_poses(data_events, data_vicon, projection_mat, window_size):
    """
    Extracts a 2d pose for each window of events.
    For each window of events generated by the specified camera, the matching Vicon poses are selected and averaged
    to create a single pose for each window, and finally projected to a 2d plane using a projection matrix.
    The matching of events and poses is based on timestamps.

    Parameters:
        data_events (dict): dictionary containing event data from all cameras, as generated by the preprocess.m matlab script
        data_vicon (dict): dictionary containing Vicon data, provided by DHP19 dataset
        projection_mat (numpy array): array with shape (4, 3) containing the projection matrix
        camera_id (int): camera id, must belong to range [0, 3]
        window_size (int): maximum number of events per window (DHP19 default is 7500)
    Returns:
        a numpy array with shape (num_of_windows, num_of_dhp19_joints, 2) containing the 2d poses
    """

    avg_poses_3d = extract_3d_poses(data_events, data_vicon, window_size)

    avg_poses_2d = project_poses_to_2d(avg_poses_3d, np.transpose(projection_mat))

    # is this needed?
    # avg_poses_2d = avg_poses_2d.astype(np.uint16)

    return avg_poses_2d


def extract_3d_poses(data_events, data_vicon, window_size):
    """
    Extracts a 3d pose for each window of events.
    For each window of events generated by the specified camera, the matching Vicon poses are selected and averaged
    to create a single pose for each window. The matching of events and poses is based on timestamps.

    Parameters:
        data_events (dict): dictionary containing event data from all cameras, as generated by the preprocess.m matlab script
        data_vicon (dict): dictionary containing Vicon data, provided by DHP19 dataset
        camera_id (int): camera id, must belong to range [0, 3]
        window_size (int): maximum number of events per window (DHP19 default is 7500)
    Returns:
        a numpy array with shape (num_of_windows, num_of_dhp19_joints, 3) containing the 3d poses
    """

    start_time = data_events['out']['extra']['startTime']
    timestamps = data_events['out']['extra']['ts']

    ##################################################################
    # for every window of events, compute the corresponding 2d pose by
    # - averaging all the 3d poses with matching timestamps
    # - projecting the average 3d pose to 2d
    ##################################################################

    window_size *= dhp19_utils.DHP19_CAM_NUM

    # compute average 3d poses
    windows_num = int(np.ceil(len(timestamps) / window_size))
    avg_poses_3d = np.zeros(shape=(windows_num, len(dhp19_utils.DHP19_BODY_PARTS), 3))
    start_ts_ind = 0
    curr_window_ind = 0
    while True:

        end_ts_ind = start_ts_ind + window_size
        window_timestamps = timestamps[start_ts_ind:end_ts_ind]

        # get indices of the 3d poses inside the window
        poses_start_ind = int(np.floor((window_timestamps[0] - start_time) * 1e-4))  # + 1
        poses_end_ind = int(np.floor((window_timestamps[-1] - start_time) * 1e-4))  # + 1

        # TODO: what if there are no poses?
        # find closest ones...

        # compute the average 3d pose
        for body_part in dhp19_utils.DHP19_BODY_PARTS:
            coords = data_vicon['XYZPOS'][body_part][poses_start_ind:poses_end_ind, :]
            avg_poses_3d[curr_window_ind, dhp19_utils.DHP19_BODY_PARTS[body_part], :] = np.nanmean(coords, axis=0)

        curr_window_ind += 1

        if end_ts_ind >= timestamps.shape[0]:
            break
        else:
            start_ts_ind = end_ts_ind

    return avg_poses_3d


def extract_3d_poses_old(data_events, data_vicon, camera_id, window_size):
    """
    Extracts a 3d pose for each window of events.
    For each window of events generated by the specified camera, the matching Vicon poses are selected and averaged
    to create a single pose for each window. The matching of events and poses is based on timestamps.

    Parameters:
        data_events (dict): dictionary containing event data from all cameras, as generated by the preprocess.m matlab script
        data_vicon (dict): dictionary containing Vicon data, provided by DHP19 dataset
        camera_id (int): camera id, must belong to range [0, 3]
        window_size (int): maximum number of events per window (DHP19 default is 7500)
    Returns:
        a numpy array with shape (num_of_windows, num_of_dhp19_joints, 3) containing the 3d poses
    """

    # # normalize events timestamps
    start_time = data_events['out']['extra']['startTime']
    # data_events['out']['data'][f'cam{camera_id}']['dvs']['ts'] = (data_events['out']['data'][f'cam{camera_id}']['dvs'][
    #                                                                'ts'] - start_time) * 1e-6
    #
    # # create an array of timestamps for the vicon's 3d poses
    # dt = 10000  # time step
    # poses_timestamps = np.arange(data_events['out']['extra']['ts'][0] - start_time,
    #                              data_events['out']['extra']['ts'][-1] - start_time + dt,
    #                              dt) * 1e-6  # Vicon timestams @ 100Hz
    # diff = len(poses_timestamps) - data_vicon['XYZPOS']['head'].shape[0]
    # if diff > 0:
    #     poses_timestamps = poses_timestamps[:-diff]

    ##################################################################
    # for every window of events, compute the corresponding 2d pose by
    # - averaging all the 3d poses with matching timestamps
    # - projecting the average 3d pose to 2d
    ##################################################################

    # compute average 3d poses
    event_window_iterator = dhp19_utils.Dhp19EventsIterator(data=data_events, cam_id=camera_id, window_size=window_size)
    avg_poses_3d = np.zeros(shape=(len(event_window_iterator), len(dhp19_utils.DHP19_BODY_PARTS), 3))
    for wi, event_window in enumerate(event_window_iterator):

        # TODO: what if event_window is empty?

        # get all 3d poses that fall into the events window
        poses_start_ind = int(np.floor((event_window[0, 0] - start_time) * 1e-4))  # + 1
        poses_end_ind = int(np.floor((event_window[-1, 0] - start_time) * 1e-4))  # + 1
        # TODO: what if there are no poses?
        # find closest ones...

        # compute the average 3d pose
        for body_part in dhp19_utils.DHP19_BODY_PARTS:
            coords = data_vicon['XYZPOS'][body_part][poses_start_ind:poses_end_ind, :]
            avg_poses_3d[wi, dhp19_utils.DHP19_BODY_PARTS[body_part], :] = np.nanmean(coords, axis=0)

    return avg_poses_3d


def project_poses_to_2d(poses_3d, projection_mat):
    """
    Projects 3d poses to a 2d plane using a projection matrix.

    Parameters:
        poses_3d (numpy array): array with shape (num_of_poses, num_of_dhp19_joints, 3) containing the input poses
        projection_mat (numpy array): array with shape (4, 3) containing the projection matrix
    Returns:
        a numpy array with shape (num_of_poses, num_of_dhp19_joints, 2) containing the projected poses
    """

    # use homogeneous coordinates representation to project 3d XYZ coordinates to 2d UV pixel coordinates
    vicon_xyz_homog = np.concatenate([poses_3d, np.ones([len(poses_3d), 13, 1])], axis=2)
    coord_pix_homog = np.matmul(vicon_xyz_homog, projection_mat)
    coord_pix_homog_norm = coord_pix_homog / np.reshape(coord_pix_homog[:, :, -1], (len(poses_3d), 13, 1))

    u = coord_pix_homog_norm[:, :, 0]
    v = dhp19_utils.DHP19_SENSOR_HEIGHT - coord_pix_homog_norm[:, :,
                                          1]  # flip v coordinate to match the image direction

    # TODO: use mask to select joints inside frame

    # mask is used to make sure that pixel positions are in frame range
    mask = np.ones(u.shape).astype(np.float32)
    mask[np.isnan(u)] = 0
    mask[np.isnan(v)] = 0
    mask[u > dhp19_utils.DHP19_SENSOR_WIDTH] = 0
    mask[u <= 0] = 0
    mask[v > dhp19_utils.DHP19_SENSOR_HEIGHT] = 0
    mask[v <= 0] = 0

    # pixel coordinates
    u = u.astype(np.int32)
    v = v.astype(np.int32)
    return np.stack((v, u), axis=-1)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Extract 2D or 3D ground truth poses from DHP19 preprocessed data files \
                                                 and save them to .npy files')
    parser.add_argument('-e', '--events_file_path', help='path to preprocessed events .mat file', required=True)
    parser.add_argument('-v', '--vicon_file_path', help='path to Vicon .mat files', required=True)
    parser.add_argument('-c', '--camera_id', help='integer [0, 3] specifying the camera id', required=True, type=int)
    parser.add_argument('-p', '--projection_matrix_file_path', help='', required=True)
    parser.add_argument('-w', '--window_size', help='', default=dhp19_utils.DHP19_CAM_FRAME_EVENTS_NUM)
    parser.add_argument('-o', '--output_folder', help='', required=True)
    parser.add_argument('-td', '--two_dimensional', dest='two_dimensional', help='', action='store_true')
    parser.set_defaults(two_dimensional=True)
    args = parser.parse_args()

    # read data from .mat files
    data_events = mat_files.loadmat(args.events_file_path)
    data_vicon = mat_files.loadmat(args.vicon_file_path)
    proj_mat = np.load(args.projection_matrix_file_path)

    if args.two_dimensional:
        poses = extract_2d_poses(data_events, data_vicon, proj_mat, args.window_size)
        file_name = f'2d_poses_cam_{args.camera_id}_{args.window_size}_events.npy'
    else:
        poses = extract_3d_poses(data_events, data_vicon, args.window_size)
        file_name = f'3d_poses_cam_{args.camera_id}_{args.window_size}_events.npy'

    np.save(os.path.join(args.output_folder, file_name), poses, allow_pickle=False)

import argparse
import numpy as np
import os

import utils as dhp19_utils
from utils import mat_files


def extract_2d_poses(data_events, data_vicon, projection_mat, window_size):
    """
    Extracts a 2d pose for each window of events.
    For each window of events generated by the specified camera, the matching Vicon poses are selected and averaged
    to create a single pose for each window, and finally projected to a 2d plane using a projection matrix.
    The matching of events and poses is based on timestamps.

    Parameters:
        data_events (dict): dictionary containing event data from all cameras, as generated by the preprocess.m matlab script
        data_vicon (dict): dictionary containing Vicon data, provided by DHP19 dataset
        projection_mat (numpy array): array with shape (4, 3) containing the projection matrix
        camera_id (int): camera id, must belong to range [0, 3]
        window_size (int): maximum number of events per window (DHP19 default is 7500)
    Returns:
        a numpy array with shape (num_of_windows, num_of_dhp19_joints, 2) containing the 2d poses
    """

    avg_poses_3d, ts = extract_3d_poses(data_events, data_vicon, window_size)

    avg_poses_2d = project_poses_to_2d(avg_poses_3d, np.transpose(projection_mat))

    # is this needed?
    # avg_poses_2d = avg_poses_2d.astype(np.uint16)

    return avg_poses_2d, ts


def extract_3d_poses(data_events, data_vicon, window_size):
    """
    Extracts a 3d pose for each window of events.
    For each window of events generated by the specified camera, the matching Vicon poses are selected and averaged
    to create a single pose for each window. The matching of events and poses is based on timestamps.

    Parameters:
        data_events (dict): dictionary containing event data from all cameras, as generated by the preprocess.m matlab script
        data_vicon (dict): dictionary containing Vicon data, provided by DHP19 dataset
        camera_id (int): camera id, must belong to range [0, 3]
        window_size (int): maximum number of events per window (DHP19 default is 7500)
    Returns:
        a numpy array with shape (num_of_windows, num_of_dhp19_joints, 3) containing the 3d poses
    """

    start_time = data_events['out']['extra']['startTime']
    timestamps = data_events['out']['extra']['ts']

    ##################################################################
    # for every window of events, compute the corresponding 2d pose by
    # - averaging all the 3d poses with matching timestamps
    # - projecting the average 3d pose to 2d
    ##################################################################

    window_size *= dhp19_utils.DHP19_CAM_NUM

    # compute average 3d poses
    windows_num = int(np.ceil(len(timestamps) / window_size))
    avg_poses_3d = np.zeros(shape=(windows_num, len(dhp19_utils.DHP19_BODY_PARTS), 3))
    ts = np.zeros(shape=(windows_num))
    start_ts_ind = 0
    curr_window_ind = 0
    while True:

        end_ts_ind = start_ts_ind + window_size
        window_timestamps = timestamps[start_ts_ind:end_ts_ind]

        # get indices of the 3d poses inside the window
        poses_start_ind = int(np.floor((window_timestamps[0] - start_time) * 1e-4))  # + 1
        poses_end_ind = int(np.floor((window_timestamps[-1] - start_time) * 1e-4))  # + 1

        # TODO: what if there are no poses?
        # find closest ones...

        # compute the average 3d pose
        for body_part in dhp19_utils.DHP19_BODY_PARTS:
            coords = data_vicon['XYZPOS'][body_part][poses_start_ind:poses_end_ind, :]
            avg_poses_3d[curr_window_ind, dhp19_utils.DHP19_BODY_PARTS[body_part], :] = np.nanmean(coords, axis=0)
        ts[curr_window_ind] = (window_timestamps[-1] - start_time) * 1e-6
        curr_window_ind += 1

        if end_ts_ind >= timestamps.shape[0]:
            break
        else:
            start_ts_ind = end_ts_ind

    return avg_poses_3d, ts


def project_poses_to_2d(poses_3d, projection_mat):
    """
    Projects 3d poses to a 2d plane using a projection matrix.

    Parameters:
        poses_3d (numpy array): array with shape (num_of_poses, num_of_dhp19_joints, 3) containing the input poses
        projection_mat (numpy array): array with shape (4, 3) containing the projection matrix
    Returns:
        a numpy array with shape (num_of_poses, num_of_dhp19_joints, 2) containing the projected poses
    """

    # use homogeneous coordinates representation to project 3d XYZ coordinates to 2d UV pixel coordinates
    vicon_xyz_homog = np.concatenate([poses_3d, np.ones([len(poses_3d), 13, 1])], axis=2)
    coord_pix_homog = np.matmul(vicon_xyz_homog, projection_mat)
    coord_pix_homog_norm = coord_pix_homog / np.reshape(coord_pix_homog[:, :, -1], (len(poses_3d), 13, 1))

    u = coord_pix_homog_norm[:, :, 0]
    v = dhp19_utils.DHP19_SENSOR_HEIGHT - coord_pix_homog_norm[:, :,
                                          1]  # flip v coordinate to match the image direction

    # TODO: use mask to select joints inside frame

    # mask is used to make sure that pixel positions are in frame range
    mask = np.ones(u.shape).astype(np.float32)
    mask[np.isnan(u)] = 0
    mask[np.isnan(v)] = 0
    mask[u > dhp19_utils.DHP19_SENSOR_WIDTH] = 0
    mask[u <= 0] = 0
    mask[v > dhp19_utils.DHP19_SENSOR_HEIGHT] = 0
    mask[v <= 0] = 0

    # pixel coordinates
    u = u.astype(np.int32)
    v = v.astype(np.int32)
    return np.stack((v, u), axis=-1)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Extract 2D or 3D ground-truth poses from DHP19 preprocessed data files \
                                                 and save them to .npy files')
    parser.add_argument('-e', '--events_file_path', help='path to preprocessed events .mat file', required=True)
    parser.add_argument('-v', '--vicon_file_path', help='path to Vicon .mat files', required=True)
    parser.add_argument('-c', '--camera_id', help='integer [0, 3] specifying the camera id', required=True, type=int)
    parser.add_argument('-p', '--projection_matrix_file_path', help='path to the projection matrix .npy file used for extracting 2D poses (use P4.npy for cam_id 0, P1 for cam_id 1, P3 for cam_id 2 and P2 for cam_id 3)', required=True)
    parser.add_argument('-w', '--window_size', help=f'approximate number of events used to compute an event frame (default value for DHP19 is {dhp19_utils.DHP19_CAM_FRAME_EVENTS_NUM})', default=dhp19_utils.DHP19_CAM_FRAME_EVENTS_NUM)
    parser.add_argument('-o', '--output_folder', help='path to the folder where output .npy file will be saved; if not present, the folder will be created', required=True)
    parser.add_argument('-td', '--two_dimensional', dest='two_dimensional', help='flag specifying if 2D poses will be extracted; if not specified, 3D poses will be extracted', action='store_true')
    parser.set_defaults(two_dimensional=False)
    args = parser.parse_args()

    # read data from .mat files
    data_events = mat_files.loadmat(args.events_file_path)
    data_vicon = mat_files.loadmat(args.vicon_file_path)

    if args.two_dimensional:
        proj_mat = np.load(args.projection_matrix_file_path)
        poses, ts = extract_2d_poses(data_events, data_vicon, proj_mat, args.window_size)
        file_name = f'2d_poses_cam_{args.camera_id}_{args.window_size}_events.npy'
        ts_file_name = f'2d_poses_cam_{args.camera_id}_{args.window_size}_ts.npy'
    else:
        poses, ts = extract_3d_poses(data_events, data_vicon, args.window_size)
        file_name = f'3d_poses_cam_{args.camera_id}_{args.window_size}_events.npy'
        ts_file_name = f'3d_poses_cam_{args.camera_id}_{args.window_size}_ts.npy'

    os.makedirs(args.output_folder, exist_ok=True)

    np.save(os.path.join(args.output_folder, file_name), poses, allow_pickle=False)
    np.save(os.path.join(args.output_folder, ts_file_name), ts, allow_pickle=False)

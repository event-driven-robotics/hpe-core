
import numpy as np
from . import constants as dhp19_const
# import constants as dhp19_const

# map from body parts to indices for dhp19
DHP19_BODY_PARTS = {
    'head': 0,
    'shoulderR': 1,
    'shoulderL': 2,
    'elbowR': 3,
    'elbowL': 4,
    'hipL': 5,
    'hipR': 6,
    'handR': 7,
    'handL': 8,
    'kneeR': 9,
    'kneeL': 10,
    'footR': 11,
    'footL': 12
}

OPENPOSE_BODY_25_TO_DHP19_INDICES = np.array([
    # TODO: compute head
    [0, DHP19_BODY_PARTS['head']],
    [2, DHP19_BODY_PARTS['shoulderR']],
    [5, DHP19_BODY_PARTS['shoulderL']],
    [3, DHP19_BODY_PARTS['elbowR']],
    [6, DHP19_BODY_PARTS['elbowL']],
    [12, DHP19_BODY_PARTS['hipL']],
    [9, DHP19_BODY_PARTS['hipR']],
    [4, DHP19_BODY_PARTS['handR']],
    [7, DHP19_BODY_PARTS['handL']],
    [10, DHP19_BODY_PARTS['kneeR']],
    [13, DHP19_BODY_PARTS['kneeL']],
    [11, DHP19_BODY_PARTS['footR']],
    [14, DHP19_BODY_PARTS['footL']]
])


def dhp19_to_hpecore_skeletons(skeletons):
    return skeletons[:, dhp19_const.DHP19_TO_HPECORE_SKELETON_IND, :]


def extract_3d_poses(data_dvs, data_vicon, window_size):
    """
    Extracts a 3d pose for each window of events.
    For each window of events generated by the specified camera, the matching Vicon poses are selected and averaged
    to create a single pose for each window. The matching of events and poses is based on timestamps.

    Parameters:
        data_dvs (dict): dictionary containing event data from all cameras, as generated by the preprocess.m matlab script
        data_vicon (dict): dictionary containing Vicon data, provided by DHP19 dataset
        window_size (int): maximum number of events per window (DHP19 default is 7500)
    Returns:
        a numpy array with shape (num_of_windows, num_of_dhp19_joints, 3) containing the 3d poses
    """

    start_time = data_dvs['out']['extra']['startTime']
    timestamps = data_dvs['out']['extra']['ts']

    ##################################################################
    # for every window of events, compute the corresponding 2d pose by
    # - averaging all the 3d poses with matching timestamps
    # - projecting the average 3d pose to 2d
    ##################################################################

    window_size *= dhp19_const.DHP19_CAM_NUM

    # compute average 3d poses
    windows_num = int(np.ceil(len(timestamps) / window_size))
    avg_poses_3d = np.zeros(shape=(windows_num, len(DHP19_BODY_PARTS), 3))
    ts = np.zeros(shape=(windows_num))
    start_ts_ind = 0
    curr_window_ind = 0
    while True:

        end_ts_ind = start_ts_ind + window_size
        window_timestamps = timestamps[start_ts_ind:end_ts_ind]

        # get indices of the 3d poses inside the window
        poses_start_ind = int(np.floor((window_timestamps[0] - start_time) * 1e-4))  # + 1
        poses_end_ind = int(np.floor((window_timestamps[-1] - start_time) * 1e-4))  # + 1

        # TODO: what if there are no poses?
        # find closest ones...

        # compute the average 3d pose
        for body_part in DHP19_BODY_PARTS:
            coords = data_vicon['XYZPOS'][body_part][poses_start_ind:poses_end_ind, :]
            avg_poses_3d[curr_window_ind, DHP19_BODY_PARTS[body_part], :] = np.nanmean(coords, axis=0)
        ts[curr_window_ind] = (window_timestamps[-1] - start_time) * 1e-6
        curr_window_ind += 1

        if end_ts_ind >= timestamps.shape[0]:
            break
        else:
            start_ts_ind = end_ts_ind

    return avg_poses_3d, ts


def get_projection_matrix(cam_id, mat_folder):

    if cam_id == 1:
        file_name = 'P1.npy'
    elif cam_id == 3:
        file_name = 'P2.npy'
    elif cam_id == 2:
        file_name = 'P3.npy'
    elif cam_id == 0:
        file_name = 'P4.npy'

    return np.load(str(mat_folder / file_name))


def openpose_to_dhp19(pose_op):
    # TODO: compute dhp19's head joints from openpose
    return pose_op[OPENPOSE_BODY_25_TO_DHP19_INDICES[:, 0], :]


def project_poses_to_2d(poses_3d, projection_mat):
    """
    Projects 3d poses to a 2d plane using a projection matrix.

    Parameters:
        poses_3d (numpy array): array with shape (num_of_poses, num_of_dhp19_joints, 3) containing the input poses
        projection_mat (numpy array): array with shape (4, 3) containing the projection matrix
    Returns:
        the projected poses (numpy array) with shape (num_of_poses, num_of_dhp19_joints, 2)
        a mask indicating if each projected joint is inside (1) or outside (0) the frame
    """

    # use homogeneous coordinates representation to project 3d XYZ coordinates to 2d UV pixel coordinates
    vicon_xyz_homog = np.concatenate([poses_3d, np.ones([len(poses_3d), 13, 1])], axis=2)
    coord_pix_homog = np.matmul(vicon_xyz_homog, projection_mat)
    coord_pix_homog_norm = coord_pix_homog / np.reshape(coord_pix_homog[:, :, -1], (len(poses_3d), 13, 1))

    u = coord_pix_homog_norm[:, :, 0]
    v = dhp19_const.DHP19_SENSOR_HEIGHT - coord_pix_homog_norm[:, :, 1]  # flip v coordinate to match the image direction

    # mask is used to make sure that pixel positions are in frame range
    mask = np.ones(u.shape).astype(np.float32)
    mask[np.isnan(u)] = 0
    mask[np.isnan(v)] = 0
    mask[u > dhp19_const.DHP19_SENSOR_WIDTH] = 0
    mask[u <= 0] = 0
    mask[v > dhp19_const.DHP19_SENSOR_HEIGHT] = 0
    mask[v <= 0] = 0

    # pixel coordinates
    u = u.astype(np.int32)
    v = v.astype(np.int32)
    return np.stack((v, u), axis=-1), mask


class Dhp19IteratorAvgPoses:

    def __init__(self, data_dvs, cam_id, window_size=dhp19_const.DHP19_CAM_FRAME_EVENTS_NUM, data_vicon=None, proj_mat_folder=None, stride=None):

        self.start_time = data_dvs['out']['extra']['startTime']

        self.timestamps = data_dvs['out']['extra']['ts']  # array containing timestamps of events from all cameras
        # self.timestamps = (self.timestamps - self.start_time) * 1e-6

        self.events = data_dvs['out']['data'][f'cam{cam_id}']['dvs']  # events specific to selected camera
        # self.events['ts'] = (self.events['ts'] - self.startTime) * 1e-6

        # events location indices follow matlab indexing convention, i.e. they start from 1 instead of 0
        self.events['x'] = self.events['x'] - 1
        self.events['y'] = self.events['y'] - 1

        # events x indices are shifted by sensor_width * camera id
        self.events['x'] = self.events['x'] - dhp19_const.DHP19_SENSOR_WIDTH * cam_id

        # events are sampled from all cameras, thus the actual window size is the desired input one (representing the
        # desired number of frames from a single camera) multiplied by the number of cameras (for an explanation, see
        # Section 4.1 of paper "DHP19: Dynamic Vision Sensor 3D Human Pose Dataset")
        self.window_size = window_size * dhp19_const.DHP19_CAM_NUM

        # defines the stride of the events' window
        self.stride = stride

        self.curr_ind = 0

        if data_vicon:
            self.vicon = data_vicon['XYZPOS']

        if proj_mat_folder:
            self.proj_mat = get_projection_matrix(cam_id, proj_mat_folder)

    def __iter__(self):
        return self

    def __len__(self):
        return int(np.ceil(len(self.timestamps) / self.window_size))

    def __next__(self):
        if self.curr_ind == -1:
            raise StopIteration

        end_ind = self.curr_ind + self.window_size

        # select events from the specified camera with timestamps within the current window
        window_timestamps = self.timestamps[self.curr_ind:end_ind]
        event_indices = np.isin(self.events['ts'], window_timestamps)
        window_events = np.concatenate((np.reshape(self.events['ts'][event_indices], (-1, 1)),
                                        np.reshape(self.events['x'][event_indices], (-1, 1)),
                                        np.reshape(self.events['y'][event_indices], (-1, 1)),
                                        np.reshape(self.events['pol'][event_indices], (-1, 1))),
                                       axis=1, dtype=np.float64)

        self.__update_current_index(end_ind)

        if self.vicon is None:
            return window_events

        # get indices of the 3d poses inside the window
        poses_start_ind = int(np.floor((window_timestamps[0] - self.start_time) * 1e-4))
        poses_end_ind = int(np.floor((window_timestamps[-1] - self.start_time) * 1e-4))
        # poses_start_ind = window_timestamps[0]
        # poses_end_ind = window_timestamps[-1]

        # compute the average 3d pose
        avg_pose_3d = np.zeros(shape=(len(DHP19_BODY_PARTS), 3))
        for body_part in DHP19_BODY_PARTS:
            coords = self.vicon[body_part][poses_start_ind:poses_end_ind, :]
            avg_pose_3d[DHP19_BODY_PARTS[body_part], :] = np.nanmean(coords, axis=0)

        if self.proj_mat is None:
            return window_events, avg_pose_3d

        # project the 3d pose to the camera plane
        avg_pose_2d, joints_mask = project_poses_to_2d(avg_pose_3d[np.newaxis, :, :], np.transpose(self.proj_mat))

        return window_events, avg_pose_2d

    def __update_current_index(self, end_ind):

        if end_ind >= self.timestamps.shape[0]:
            self.curr_ind = -1
        else:
            if self.stride:
                self.curr_ind += self.stride
                if self.curr_ind >= self.timestamps.shape[0]:
                    self.curr_ind = -1
            else:
                self.curr_ind = end_ind


class Dhp19Iterator:

    def __init__(self, data_dvs, cam_id, data_vicon=None, proj_mat_folder=None):

        self.start_time = data_dvs['out']['extra']['startTime']

        self.timestamps = data_dvs['out']['extra']['ts']  # array containing timestamps of events from all cameras
        # self.timestamps = (self.timestamps - self.start_time) * 1e-6

        self.events = data_dvs['out']['data'][f'cam{cam_id}']['dvs']  # events specific to selected camera
        # self.events['ts'] = (self.events['ts'] - self.startTime) * 1e-6

        # events location indices follow matlab indexing convention, i.e. they start from 1 instead of 0
        self.events['x'] = self.events['x'] - 1
        self.events['y'] = self.events['y'] - 1

        # events x indices are shifted by sensor_width * camera id
        self.events['x'] = self.events['x'] - dhp19_const.DHP19_SENSOR_WIDTH * cam_id

        self.poses = data_vicon['XYZPOS']

        self.curr_pose_ind = 0

        if proj_mat_folder:
            self.proj_mat = get_projection_matrix(cam_id, proj_mat_folder)

    def __iter__(self):
        return self

    def __len__(self):
        return self.poses['head'].shape[0]

    def __next__(self):
        if self.curr_pose_ind == -1:
            raise StopIteration

        # get past and current pose index
        self.prev_pose_ind = self.curr_pose_ind
        self.curr_pose_ind += 1

        # convert pose indices to event timestamps
        prev_pose_ts = self.prev_pose_ind * 10000 + self.start_time
        curr_pose_ts = self.curr_pose_ind * 10000 + self.start_time

        # select events between the previous and current poses' timestamps
        event_indices = prev_pose_ts < self.events['ts']
        event_indices = event_indices & (self.events['ts'] <= curr_pose_ts)
        window_events = np.concatenate((np.reshape(self.events['ts'][event_indices], (-1, 1)),
                                        np.reshape(self.events['x'][event_indices], (-1, 1)),
                                        np.reshape(self.events['y'][event_indices], (-1, 1)),
                                        np.reshape(self.events['pol'][event_indices], (-1, 1))),
                                       axis=1, dtype=np.float64)

        self.__update_current_index()

        # get the 3d pose
        pose_3d = np.zeros(shape=(len(DHP19_BODY_PARTS), 3))
        for body_part in DHP19_BODY_PARTS:
            coords = self.poses[body_part][self.curr_pose_ind, :]
            pose_3d[DHP19_BODY_PARTS[body_part], :] = coords

        if self.proj_mat is None:
            return window_events, pose_3d

        # project the 3d pose to the camera plane
        pose_2d, joints_mask = project_poses_to_2d(pose_3d[np.newaxis, :, :], np.transpose(self.proj_mat))

        return window_events, pose_2d[0]

    def __update_current_index(self):

        if self.curr_pose_ind >= self.poses['head'].shape[0]:
            self.curr_pose_ind = -1
        else:
            self.curr_pose_ind += 1
